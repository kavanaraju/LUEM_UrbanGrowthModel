---
title: "CPLN 6750 – Phoenix Urban Growth Forecast, 2031"
author:
  - "Sravya Dandamudi"
  - "Kavana Raju"
date: "5/10/2025"
output:
  html_document:
    theme: flatly
    highlight: tango
    toc: true
    toc_float: true
    code_folding: hide    
    code_download: yes
knitr:
  opts_chunk:
    echo: true           
    warning: false  
    message: false
---

**To:** Joshua Bednarek  
**From:** Sravya Dandamudi & Kavana Raju  
**Date:** May 10, 2025  
**Subject:** Spatial Forecast of the Phoenix MSA for 2031

# 1. Objective 

Phoenix’s Planning and Development Department needs a data-driven projection of urban growth to inform the next comprehensive plan. We examine how proximity to existing and a proposed northwest light-rail extension shaped development from 2011–2021, build a logistic regression model, and then forecast where new development is most likely by 2031 under the extension scenario. This supports targeted growth management and conservation.

```{r setup, include=FALSE}
# Load packages
pkgs <- c(
  "tidyverse","sf","raster","terra","exactextractr",
  "tidycensus","tigris","FNN","caret","yardstick","plotROC",
  "kableExtra","mapview","FedData"
)
lapply(pkgs, function(p) if(!requireNamespace(p,quietly=TRUE)) install.packages(p))
lapply(pkgs, library, character.only=TRUE)

# Custom helper functions (from class exercise)
quintileBreaks <- function(df, variable) {
  as.character(quantile(df[[variable]], c(.01,.2,.4,.6,.8), na.rm=TRUE))
}
xyC <- function(aPolygonSF) {
  as.data.frame(cbind(
    x=st_coordinates(st_centroid(aPolygonSF))[,1],
    y=st_coordinates(st_centroid(aPolygonSF))[,2]
  ))
}
rast <- function(inRaster) {
  df <- data.frame(xyFromCell(inRaster, 1:ncell(inRaster)),
                   value=getValues(inRaster))
  colnames(df) <- c('x','y','value')
  df}

nn_function <- function(measureFrom, measureTo, k) {
  mf <- as.matrix(measureFrom)
  mt <- as.matrix(measureTo)
  dists <- get.knnx(mt, mf, k)$nn.dist
  rowMeans(dists)}

aggregateRaster <- function(inputRasterList, fishnet) {
  rasters     <- raster::stack(inputRasterList)
  layer_names <- names(rasters)
  result      <- fishnet

  counts <- raster::extract(
    rasters,
    result,
    fun = function(x, ...) {
      if (is.null(dim(x))) {
        sum(x == 1, na.rm = TRUE)
      } else {
        colSums(x == 1, na.rm = TRUE)
      }
    }
  )

  if (is.vector(counts)) {
    counts <- matrix(counts, ncol = nlayers(rasters))
  }
  colnames(counts) <- layer_names

  for (nm in layer_names) {
    result[[nm]] <- as.integer(counts[, nm] > 0)
  }
  result
}
```

# 2. Exploratory Analysis

We first load the MSA boundary and NLCD land cover for 2011/2021, reclassify to “developed” (21–24), and visualize.

```{r load-boundary-nlcd}
# Load Boundary for Phoenix
phx_msa <- st_read("data/Phoenix_MSA/Phoenix_MSA.shp", quiet=TRUE) %>%
  st_transform(26912)  # NAD83 / Arizona Central

# Load NLCDrasters
lc_2011 <- raster("data/Annual_NLCD_LndCov_2011_CU_C1V0.tif")  
lc_2021 <- raster("data/Annual_NLCD_LndCov_2021_CU_C1V0.tif")

# Transform the MSA boundary to match the raster CRS
phx_msa_r <- st_transform(phx_msa, crs(lc_2011))

# Crop and mask the country-wide rasters to the Phoenix MSA boundary
lc_2011 <- crop(lc_2011, phx_msa_r)
lc_2011 <- mask(lc_2011, phx_msa_r)

lc_2021 <- crop(lc_2021, phx_msa_r)
lc_2021 <- mask(lc_2021, phx_msa_r)

# Reproject masked rasters back to study CRS
lc_2011 <- projectRaster(lc_2011, crs = 26912)
lc_2021 <- projectRaster(lc_2021, crs = 26912)

# Reclassify developed classes (NLCD 21–24)
rc <- matrix(c(0,12,0, 12,24,1, 24,Inf,0), ncol=3, byrow=TRUE)
dev1 <- reclassify(lc1_rs, rc)
dev2 <- reclassify(lc2_rs, rc)

plot(dev2, main="2021 Developed Land (NLCD 21–24)")
```

Figure 1. Developed land footprint in 2021.

```{r save-lc}
writeRaster(
  x         = lc_2011,
  filename  = "data/LC_2011_PhoenixMSA",
  filetype  = "GTiff",
  overwrite = TRUE)

writeRaster(
  x         = lc_2021,
  filename  = "data/LC_2021_PhoenixMSA",
  filetype  = "GTiff",
  overwrite = TRUE)
```

# 3. Land Cover Conversion (2011→2021)

We detect cells converting from undeveloped to developed.

```{r detect-change}
# Resample to 300m (To capture finer details as we're analyzing the extension - TOD)
lc1_rs <- aggregate(lc_2011, fact=10, fun="modal")
lc2_rs <- aggregate(lc_2021, fact=10, fun="modal")

# Align origins, resolution, and extent
lc2_rs <- resample(lc2_rs, lc1_rs, method="ngb")

# Map algebra: 1 = change from undeveloped to developed
dev_change <- dev1 + dev2
# Keep only converted cells
dev_change[dev_change != 1] <- NA

plot(dev_change, main="Converted to Developed (2011–2021)")
```

# 4. Fishnet Grid & Raster Aggregation

Create a 300 m fishnet and aggregate land-cover flags.

```{r fishnet-raster-join}
grid_res <- res(lc1_rs)[1] #cell size

# 1. Build the full grid over the MSA bounding box only
bbox      <- st_bbox(phx_msa)
grid_full <- st_make_grid(
  phx_msa,
  cellsize = grid_res,
  square   = TRUE,
  offset   = c(bbox$xmin, bbox$ymin),
  n        = c(
    ceiling((bbox$xmax - bbox$xmin) / grid_res),
    ceiling((bbox$ymax - bbox$ymin) / grid_res)))

# 2. Convert to sf
grid_sf   <- st_sf(grid = grid_full)

# 3. Compute centroids once (cheap)
centroids <- st_centroid(grid_sf)

# 4. Keep only cells whose centroid lies _inside_ the MSA
inside    <- st_within(centroids, phx_msa, sparse = FALSE)[,1]
fishnet   <- grid_sf[inside, ]

# 5. Assign unique IDs
fishnet <- fishnet %>% mutate(cell_id = row_number())

# Convert the change raster to points
pts_change <- rasterToPoints(dev_change) %>% 
  as.data.frame() %>% 
  st_as_sf(coords = c('x','y'), crs = st_crs(fishnet))

# Aggregate change points to fishnet grid
fishnet <- aggregate(pts_change, fishnet, FUN = sum) %>%
  mutate(development_change = factor(ifelse(layer > 0, 1, 0))) %>%
  dplyr::select(-layer)


#Aggregating Land Cover Categories

# 0. Ensure 'cell_id' exists on fishnet
if (!"cell_id" %in% names(fishnet)) {
  fishnet <- fishnet %>% mutate(cell_id = row_number())
}

# 1. Convert fishnet sf → SpatVector
sv <- terra::vect(fishnet)

# ---- 2011 land-cover categories ----

# 2. Build SpatRaster stack of your 2011 binaries
# collect 2011 binaries into a list
rasters1 <- list(
  dev1    = dev1,
  forest1 = forest1,
  farm1   = farm1,
  wet1    = wet1,
  oth1    = oth1,
  water1  = water1
)

stack1 <- raster::stack(rasters1)   # RasterStack of dev1, forest1, etc.
s1      <- terra::rast(stack1)      # now a SpatRaster; names already correct

# 3. Rasterize zones (cell_id) onto the same grid
template_rast <- s1[[1]]  
zoneR         <- terra::rasterize(sv, template_rast, field = "cell_id")

# 4. Zonal‐sum all layers in one C‐level call
counts1 <- terra::zonal(s1, zoneR, fun = "sum", na.rm = TRUE)

# 5. Convert to data.frame, join back, and flag >0 → 1/0
df1 <- as.data.frame(counts1)
colnames(df1)[1] <- "cell_id"

fishnet_lc1 <- fishnet %>%
  left_join(df1, by = "cell_id") %>%
  mutate(across(.cols = names(s1), ~ as.integer(.x > 0)))

# ---- 2021 land-cover categories ----

# 6. Build SpatRaster stack of your 2021 binaries
# collect 2021 binaries into a list
rasters2 <- list(
  dev2    = dev2,
  forest2 = forest2,
  farm2   = farm2,
  wet2    = wet2,
  oth2    = oth2)

stack2 <- raster::stack(rasters2)
s2      <- terra::rast(stack2)      # names carry over from rasters2

# 7. Zonal‐sum onto the same zoneR
counts2 <- terra::zonal(s2, zoneR, fun = "sum", na.rm = TRUE)

# 8. Convert, join, and flag >0 → 1/0
df2 <- as.data.frame(counts2)
colnames(df2)[1] <- "cell_id"

fishnet_lc2 <- fishnet %>%
  left_join(df2, by = "cell_id") %>%
  mutate(across(.cols = names(s2), ~ as.integer(.x > 0)))

```

# 5. Census & Infrastructure Predictors

We interpolate 2011/2021 tract pop, income, housing to grid and compute distances.

```{r census}
census_api_key("52f0462d8b4e1e19ee64b25a3196677c5e32e660", install=FALSE)

# Variables: total population, median income, housing units
tidy_vars <- c(pop = "B01003_001E",
               income = "B19013_001E",
               housing = "B25001_001E")

# Specify counties for Phoenix MSA
counties <- c("Maricopa", "Pinal")

# Download 2011 ACS (wide format) and rename estimate columns
acs11 <- get_acs(
  geography = "tract",
  variables = tidy_vars,
  year = 2011,
  state = "AZ",
  county = counties,
  geometry = TRUE,
  output = "wide"
) %>%
  st_transform(st_crs(fishnet)) %>%
  rename(
    pop11 = pop,
    inc11 = income,
    house11 = housing
  ) %>%
  dplyr::select(GEOID, pop11, inc11, house11, geometry)

# Download 2021 ACS (wide format) and rename estimate columns
acs21 <- get_acs(
  geography = "tract",
  variables = tidy_vars,
  year = 2021,
  state = "AZ",
  county = counties,
  geometry = TRUE,
  output = "wide"
) %>%
  st_transform(st_crs(fishnet)) %>%
  rename(
    pop21 = pop,
    inc21 = income,
    house21 = housing
  ) %>%
  dplyr::select(GEOID, pop21, inc21, house21, geometry)

# Areal-weighted interpolation onto fishnet
fishnet_pop11 <- st_interpolate_aw(
  acs11[c("pop11", "inc11", "house11")],
  fishnet,
  extensive = TRUE
)
fishnet_pop21 <- st_interpolate_aw(
  acs21[c("pop21", "inc21", "house21")],
  fishnet,
  extensive = TRUE
)

#Transportation & Infrastructure Features

# Load existing light rail network
existing_lr <- st_read("data/LightRail_Existing/LightRail_Existing.shp")

existing_lr <- st_transform(existing_lr, st_crs(fishnet))

# Compute distance from each cell centroid to nearest existing light rail line
centroids <- st_centroid(fishnet)
fishnet$dist_lr_existing <- as.numeric(
  st_distance(centroids, st_union(existing_lr)))

# Proposed extension
new_lr <- st_read("data/LightRail_Extension/LightRail_Extension.shp")

new_lr <- st_transform(new_lr, st_crs(fishnet))

fishnet$dist_new <- as.numeric(st_distance(centroids, new_lr))

# Compute centroids once
centroids <- st_centroid(fishnet)
# Matrix of fishnet centroid coordinates
grid_xy <- st_coordinates(centroids)

# Extract fishnet_lc layers: dev1 and dev2 should already be numeric 0/1 columns
# No need to re-mutate dev1/dev2

# Points of converted cells in t1 and t2
t1_points <- fishnet_lc1 %>%
  filter(dev1 == 1) %>%        # dev1 is numeric vector
  st_centroid() %>%
  st_coordinates()
t2_points <- fishnet_lc2 %>%
  filter(dev2 == 1) %>%
  st_centroid() %>%
  st_coordinates()

# Compute spatial lag: average distance to 2 nearest developed cells
grid_lag1 <- nn_function(grid_xy, t1_points, k = 2)
grid_lag2 <- nn_function(grid_xy, t2_points, k = 2)

# Attach lag variables back to fishnet
fishnet <- fishnet %>%
  mutate(
    lagDev1 = grid_lag1,
    lagDev2 = grid_lag2
  )

cts <- counties(state="AZ", cb=TRUE) %>% st_transform(st_crs(fishnet)) %>%
  filter(NAME %in% c("Maricopa","Pinal"))
fishnet <- fishnet %>% st_join(cts["NAME"]) %>% rename(county=NAME)
```

# 6. Model Training & Validation

Assemble 2011 predictors and fit logistic regression.

```{r compile}
# ─────────────────────────────────────────────────────────────────────────────
# 0. Recompute and prepare the 2011 population/census table, ensuring one row per cell_id
# ─────────────────────────────────────────────────────────────────────────────
fishnet_pop11 <- st_interpolate_aw(
  acs11[c("pop11","inc11","house11")],
  fishnet,
  extensive = TRUE)

# Attach the matching cell_id from fishnet
pop11_df <- fishnet_pop11 %>%
  st_drop_geometry() %>%
  mutate(cell_id = fishnet$cell_id) %>%
  dplyr::select(cell_id, pop11, inc11, house11) %>%
  distinct(cell_id, .keep_all = TRUE)

# ─────────────────────────────────────────────────────────────────────────────
# 1. Land‐cover flags (base_lc1)
# ─────────────────────────────────────────────────────────────────────────────
base_lc1 <- fishnet_lc1 %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, dev1, forest1, farm1, wet1, oth1, water1) %>%
  distinct(cell_id, .keep_all = TRUE)

# ─────────────────────────────────────────────────────────────────────────────
# 2. Change + distance + lag + county
# ─────────────────────────────────────────────────────────────────────────────
fishnet_df <- fishnet %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, development_change, county, dist_lr_existing, dist_new, lagDev1)

# ─────────────────────────────────────────────────────────────────────────────
# 3. Assemble the 2011 training dataset
# ─────────────────────────────────────────────────────────────────────────────
dat11 <- base_lc1 %>%
  left_join(fishnet_df, by = "cell_id") %>%
  left_join(pop11_df,   by = "cell_id") %>%
  filter(wet1 == 0) %>%
  # HERE: recode any NA → 0 on development_change
  mutate(
    development_change = as.character(development_change),  # to avoid factor quirks
    development_change = replace_na(development_change, "0"),
    development_change = factor(development_change, levels = c("0","1"))
  )

dat11 <- dat11 %>%
  # Impute median income for any missing cells
  mutate(
    inc11 = replace_na(inc11, median(inc11, na.rm = TRUE))
  )

# sanity check
table(dat11$development_change)
colSums(is.na(dat11))

set.seed(2025)
train_i <- caret::createDataPartition(
  y    = dat11$development_change,
  p    = 0.70,
  list = FALSE
)
train <- dat11[train_i, ]
test  <- dat11[-train_i, ]

# Check class balance
prop.table(table(train$development_change))
prop.table(table(test$development_change))

# 14.2. Fit the Logistic Regression Model
model <- glm(
  development_change ~ 
    dist_lr_existing + dist_new + lagDev1 +
    pop11  + inc11   + house11 +
    dev1   + forest1 + farm1   + oth1   +
    county,
  data   = train,
  family = binomial(link = "logit")
)
summary(model)

# 14.3. Predict on Test Set
test$prob <- predict(model, test, type = "response")

# 14.4. Choose Threshold & Confusion Matrix
threshold <- 0.10
test$pred_class <- factor(
  ifelse(test$prob > threshold, "1", "0"),
  levels = c("0","1")
)
cm <- caret::confusionMatrix(
  test$pred_class,
  factor(test$development_change),
  positive = "1"
)
print(cm)
```

Table 1. Model summary (see summary(model)).
Table 2. Confusion matrix (threshold=0.10): Sensitivity=r cm$byClass["Sensitivity"], Specificity=r cm$byClass["Specificity"].
Figure 2. ROC (AUC=r round(auc_val,2)).

> - **Coefficients:** signs, significance, and e^(β) for interpretation  
> - **Confusion matrix:** accuracy, sensitivity (TPR), specificity (TNR) at your chosen threshold  
> - **AUC** from the ROC (should be ≥ 0.7 for a useful model)

```{r plot-roc}
# 14.5. ROC Curve & AUC
library(plotROC)
roc_df <- data.frame(
  obs  = as.numeric(test$development_change),
  pred = test$prob
)
ggplot(roc_df, aes(d = obs, m = pred)) +
  geom_roc(n.cuts = 50) +
  style_roc(theme = theme_minimal()) +
  labs(title = "ROC Curve (Test Set)")

library(yardstick)
auc_val <- roc_auc_vec(test$development_change, test$prob)
cat("Test‐set AUC =", round(auc_val, 3), "\n")
```

# 7. Forecast to 2031 & Impact Assessment

Apply model to 2021 inputs + new corridor, map projected development, and assess risk.

```{r forecast}

# 15A. Build the raw t2 feature table (from fishnet_lc2, fishnet, fishnet_pop21) ---

# 1. LC flags
lc2_df <- fishnet_lc2 %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, dev2, forest2, farm2, wet2, oth2)

# 2. Infra, lag, county
feat2_df <- fishnet %>%
  st_drop_geometry() %>%
  rename(dist_hwy = dist_lr_existing) %>%    # keep same name as in t1 compile
  dplyr::select(cell_id, dist_hwy, dist_new, lagDev2, county)

# 3. Census via spatial join (one-to-one to fishnet)
pop21_df <- fishnet_pop21 %>%
  st_centroid() %>%
  st_join(dplyr::select(fishnet, cell_id), join = st_within) %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, pop21, inc21, house21) %>%
  distinct(cell_id, .keep_all = TRUE)

# 4. Left‐join all and filter water
dat21 <- lc2_df %>%
  left_join(feat2_df, by = "cell_id") %>%
  left_join(pop21_df,  by = "cell_id") %>%
  filter(wet2 == 0)

# --- 15B. Rename to match t1 variable names exactly ---

dat21 <- dat21 %>%
  rename(
    lagDev1  = lagDev2,   # model expects lagDev1
    pop11    = pop21,     
    inc11    = inc21,
    house11  = house21,
    dev1     = dev2,      # model uses dev1, forest1, farm1, oth1
    forest1  = forest2,
    farm1    = farm2,
    oth1     = oth2,
    dist_lr_existing = dist_hwy  # if your model uses dist_lr_existing
  )

# Drop the old t2-named cols to avoid confusion
dat21 <- dat21 %>% dplyr::select(
  cell_id,
  dist_lr_existing, dist_new, lagDev1,
  pop11, inc11, house11,
  dev1, forest1, farm1, oth1,
  county
)

# 15C. Impute any remaining NAs
dat21 <- dat21 %>%
  mutate(
    pop11   = replace_na(pop11,   0),
    house11 = replace_na(house11, 0),
    inc11   = replace_na(inc11,   median(inc11, na.rm=TRUE))
  )

# Verify zero NAs
cat("NAs in dat21:", sum(is.na(dat21)), "\n")

# --- 15D. Predict 2031 Development ---

dat21$prob31 <- predict(model, dat21, type = "response")

threshold <- 0.10
dat21$pred31 <- factor(
  ifelse(dat21$prob31 > threshold, "1", "0"),
  levels = c("0","1")
)

# --- 15E. Join back to fishnet and assess risk ---

forecast_sf <- left_join(fishnet, dat21, by = "cell_id")
```
> 1. **Map** of cells predicted to develop by 2031.  
> 2. **Table** showing `% in floodplain` and `% in protected areas`.  
> 3. **Narrative** tying these numbers to your three key recommendations.

```{r impact-assessment, warning=FALSE, message=FALSE}
gdb_path <- "data/Protected Areas/PADUS4_1_StateAZ.gdb"
st_layers(gdb_path)

# 2. Read the Fee‐simple layer (clean multipolygons only)
prot_fee <- st_read(
  dsn   = gdb_path,
  layer = "PADUS4_1Fee_State_AZ",   # simpler, pure multipolygon layer
  quiet = TRUE
)

# 3. Drop any Z/M dims and ensure POLYGON/MULTIPOLYGON
prot <- prot_fee %>%
  st_zm(drop = TRUE, what = "ZM") %>%    # strip Z/M
  st_cast("MULTIPOLYGON") %>%            # force to standard multipolygons
  st_transform(st_crs(forecast_sf))      # into your model CRS


# 4. Flag protected‐area risk
# 1. One-time spatial intersection call
ix <- st_intersects(forecast_sf, prot)

# 2. Logical vector: does each cell touch protected area?
touches_prot <- lengths(ix) > 0

# 3. Add prot_risk in two quick steps
forecast_sf$prot_risk <- (forecast_sf$pred31 == "1") & touches_prot

# 5. Summarize
risk_sum <- forecast_sf %>%
  filter(pred31 == "1") %>%
  st_drop_geometry() %>%
  summarize(
    total_cells = n(),
    pct_prot    = mean(prot_risk) * 100
  )
knitr::kable(risk_sum, digits = 1,
             caption = "Percent of 2031‐Predicted Cells in Fee‐Simple Protected Areas")

dev_area <- forecast_sf %>% 
  filter(pred31 == "1") %>% 
  st_union() %>% 
  st_as_sf()

ggplot() +
  # 1. white background & crisp outline of study area
  geom_sf(data = phx_msa, fill = "white", color = "black", size = 0.5) +
  
  # 2. plotted development forecast
  geom_sf(data = dev_area, fill = "darkgreen", color = NA) +
  
  # 3. updated legend with no "NA" class
  scale_fill_manual(
    values       = c("0" = "grey80", "1" = "darkgreen"),
    labels       = c("No Dev", "Developed"),
    name         = "2031 Dev",
    na.value     = "white",      # paint any missing cells white
    na.translate = FALSE         # drop the “NA” entry from the legend
  ) +
  
  # 4. titles & clean theme
  labs(
    title    = "Projected 2031 Development",
    subtitle = "Threshold = 10%"
  ) +
  theme_void() +
  theme(
    plot.title    = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    legend.position = "right"
  )
```
```{r}
save.image(file = "data/my_workspace.RData")

load("data/my_workspace.RData")
```

# 8. Key Recommendations


---

<small>Adapted from Houston Urban Growth Modeling example (Fichman et al.).</small>
