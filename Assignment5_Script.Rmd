---
title: "CPLN 6750 – Phoenix Urban Growth Forecast, 2031"
author:
  - "Sravya Dandamudi"
  - "Kavana Raju"
date: "5/10/2025"
output:
  html_document:
    theme: flatly
    highlight: tango
    toc: true
    toc_float: true
    code_folding: hide    
    code_download: yes
knitr:
  opts_chunk:
    echo: true           
    warning: false  
    message: false
---

**To:** Joshua Bednarek  
**From:** Sravya Dandamudi & Kavana Raju  
**Date:** May 10, 2025  
**Subject:** Spatial Forecast of the Phoenix MSA for 2031

# Objective 

Phoenix’s Planning and Development Department has started talking about creating the next comprehensive plan to ensure that the city has the proper guidance and information to invest in its future. To inform their decision-making, since comprehensive plans are looking at multiple different aspects of the city including the environment, economy, transportation, housing, etc, it is important to think about what land uses will look like in 2031. Phoenix has a new proposed light rail extension, so we looked at how this addition affects the way land is developed since it has a significant effect in how people move and what they able to access which would affect how land is developed. We looked at how different variables affected land use between 2011-2021 and then used those findings to see how land use would change for 2031.

```{r setup, include=FALSE}
# Load packages
pkgs <- c(
  "tidyverse","sf","raster","terra","exactextractr",
  "tidycensus","tigris","FNN","caret","yardstick","plotROC",
  "kableExtra","mapview","FedData"
)
lapply(pkgs, function(p) if(!requireNamespace(p,quietly=TRUE)) install.packages(p))
lapply(pkgs, library, character.only=TRUE)

# Custom helper functions (from class exercise)
quintileBreaks <- function(df, variable) {
  as.character(quantile(df[[variable]], c(.01,.2,.4,.6,.8), na.rm=TRUE))
}
xyC <- function(aPolygonSF) {
  as.data.frame(cbind(
    x=st_coordinates(st_centroid(aPolygonSF))[,1],
    y=st_coordinates(st_centroid(aPolygonSF))[,2]
  ))
}
rast <- function(inRaster) {
  df <- data.frame(xyFromCell(inRaster, 1:ncell(inRaster)),
                   value=getValues(inRaster))
  colnames(df) <- c('x','y','value')
  df}

nn_function <- function(measureFrom, measureTo, k) {
  mf <- as.matrix(measureFrom)
  mt <- as.matrix(measureTo)
  dists <- get.knnx(mt, mf, k)$nn.dist
  rowMeans(dists)}

aggregateRaster <- function(inputRasterList, fishnet) {
  rasters     <- raster::stack(inputRasterList)
  layer_names <- names(rasters)
  result      <- fishnet

  counts <- raster::extract(
    rasters,
    result,
    fun = function(x, ...) {
      if (is.null(dim(x))) {
        sum(x == 1, na.rm = TRUE)
      } else {
        colSums(x == 1, na.rm = TRUE)
      }
    }
  )

  if (is.vector(counts)) {
    counts <- matrix(counts, ncol = nlayers(rasters))
  }
  colnames(counts) <- layer_names

  for (nm in layer_names) {
    result[[nm]] <- as.integer(counts[, nm] > 0)
  }
  result
}
```

# 1. Introduction

This report builds a spatial logistic regression model of urban development in the Phoenix–Mesa–Scottsdale MSA, using land cover change from 2011 to 2021 as training data. We then forecast development to 2031 under a scenario where a new transportation corridor is introduced. Finally, we assess where sensitive lands (flood zones, protected areas) are at risk and propose planning recommendations.

# 2. Workflow Overview

1. Import and preprocess land cover rasters (2011, 2021)  
2. Reclassify to developed/undeveloped and derive change raster  
3. Build a fishnet grid and aggregate raster and vector features to each cell  
4. Engineer predictors: distance to roads, spatial lag, census variables, slope  
5. Train logistic regression model (2011→2021) and validate  
6. Forecast to 2031 using 2021 inputs + extension scenario  
7. Assess impacts on sensitive lands  
8. Key recommendations

# 3. Study Area Boundary

```{r load-boundary}
# Load Boundary for Phoenix
phx_msa <- st_read("data/Phoenix_MSA/Phoenix_MSA.shp", quiet=TRUE) %>%
  st_transform(26912)  # NAD83 / Arizona Central
```

# 4. Load Land Cover Data (NLCD)

```{r load-nlcd}
# Load NLCDrasters
lc_2011 <- raster("data/Annual_NLCD_LndCov_2011_CU_C1V0.tif")  
lc_2021 <- raster("data/Annual_NLCD_LndCov_2021_CU_C1V0.tif")

# Transform the MSA boundary to match the raster CRS
phx_msa_r <- st_transform(phx_msa, crs(lc_2011))

# Crop and mask the country-wide rasters to the Phoenix MSA boundary
lc_2011 <- crop(lc_2011, phx_msa_r)
lc_2011 <- mask(lc_2011, phx_msa_r)

lc_2021 <- crop(lc_2021, phx_msa_r)
lc_2021 <- mask(lc_2021, phx_msa_r)

# Reproject masked rasters back to study CRS
lc_2011 <- projectRaster(lc_2011, crs = 26912)
lc_2021 <- projectRaster(lc_2021, crs = 26912)
```

```{r save-lc}
writeRaster(
  x         = lc_2011,
  filename  = "data/LC_2011_PhoenixMSA",
  filetype  = "GTiff",
  overwrite = TRUE)

writeRaster(
  x         = lc_2021,
  filename  = "data/LC_2021_PhoenixMSA",
  filetype  = "GTiff",
  overwrite = TRUE)
```

# 5. Detecting Land Cover Conversion

```{r detect-change}
# Resample to 300m (To capture finer details as we're analyzing the extension - TOD)
lc1_rs <- aggregate(lc_2011, fact=10, fun="modal")
lc2_rs <- aggregate(lc_2021, fact=10, fun="modal")

# Align origins, resolution, and extent
lc2_rs <- resample(lc2_rs, lc1_rs, method="ngb")

# Reclassify developed classes (NLCD 21–24)
rc <- matrix(c(0,12,0, 12,24,1, 24,Inf,0), ncol=3, byrow=TRUE)
dev1 <- reclassify(lc1_rs, rc)
dev2 <- reclassify(lc2_rs, rc)

# Map algebra: 1 = change from undeveloped to developed
# dev1=0 & dev2=1 => converted; dev1=1 & dev2=0 => unlikely here
dev_change <- dev1 + dev2
# Keep only converted cells
dev_change[dev_change != 1] <- NA
```

# 6. Creating the Fishnet Grid

```{r fishnet}
grid_res <- res(lc1_rs)[1] #cell size

#For Faster Processing as the Cell Size is Small
# 1. Build the full grid over the MSA bounding box only
bbox      <- st_bbox(phx_msa)
grid_full <- st_make_grid(
  phx_msa,
  cellsize = grid_res,
  square   = TRUE,
  offset   = c(bbox$xmin, bbox$ymin),
  n        = c(
    ceiling((bbox$xmax - bbox$xmin) / grid_res),
    ceiling((bbox$ymax - bbox$ymin) / grid_res)
  )
)

# 2. Convert to sf
grid_sf   <- st_sf(grid = grid_full)

# 3. Compute centroids once (cheap)
centroids <- st_centroid(grid_sf)

# 4. Keep only cells whose centroid lies _inside_ the MSA
inside    <- st_within(centroids, phx_msa, sparse = FALSE)[,1]
fishnet   <- grid_sf[inside, ]

# 5. Assign unique IDs
fishnet <- fishnet %>% mutate(cell_id = row_number())
```

# 7. Join Raster Change to Fishnet

```{r join-change}
# Convert the change raster to points
pts_change <- rasterToPoints(dev_change) %>% 
  as.data.frame() %>% 
  st_as_sf(coords = c('x','y'), crs = st_crs(fishnet))

# Aggregate change points to fishnet grid
fishnet <- aggregate(pts_change, fishnet, FUN = sum) %>%
  mutate(development_change = factor(ifelse(layer > 0, 1, 0))) %>%
  dplyr::select(-layer)
```

# 8. Aggregating Land Cover Categories
```{r}
library(terra)
library(raster)
library(dplyr)

# 0. Ensure 'cell_id' exists on fishnet
if (!"cell_id" %in% names(fishnet)) {
  fishnet <- fishnet %>% mutate(cell_id = row_number())
}

# 1. Convert fishnet sf → SpatVector
sv <- terra::vect(fishnet)

# ---- 2011 land-cover categories ----

# 2. Build SpatRaster stack of your 2011 binaries
stack1 <- raster::stack(rasters1)   # RasterStack of dev1, forest1, etc.
s1      <- terra::rast(stack1)      # now a SpatRaster; names already correct

# 3. Rasterize zones (cell_id) onto the same grid
template_rast <- s1[[1]]  
zoneR         <- terra::rasterize(sv, template_rast, field = "cell_id")

# 4. Zonal‐sum all layers in one C‐level call
counts1 <- terra::zonal(s1, zoneR, fun = "sum", na.rm = TRUE)

# 5. Convert to data.frame, join back, and flag >0 → 1/0
df1 <- as.data.frame(counts1)
colnames(df1)[1] <- "cell_id"

fishnet_lc1 <- fishnet %>%
  left_join(df1, by = "cell_id") %>%
  mutate(across(.cols = names(s1), ~ as.integer(.x > 0)))

# ---- 2021 land-cover categories ----

# 6. Build SpatRaster stack of your 2021 binaries
stack2 <- raster::stack(rasters2)
s2      <- terra::rast(stack2)      # names carry over from rasters2

# 7. Zonal‐sum onto the same zoneR
counts2 <- terra::zonal(s2, zoneR, fun = "sum", na.rm = TRUE)

# 8. Convert, join, and flag >0 → 1/0
df2 <- as.data.frame(counts2)
colnames(df2)[1] <- "cell_id"

fishnet_lc2 <- fishnet %>%
  left_join(df2, by = "cell_id") %>%
  mutate(across(.cols = names(s2), ~ as.integer(.x > 0)))

```

# 9. Population & Socioeconomic Data via tidycensus

```{r census}
census_api_key("52f0462d8b4e1e19ee64b25a3196677c5e32e660", install=FALSE)

# Variables: total population, median income, housing units
tidy_vars <- c(pop = "B01003_001E",
               income = "B19013_001E",
               housing = "B25001_001E")

# Specify counties for Phoenix MSA
counties <- c("Maricopa", "Pinal")

# Download 2011 ACS (wide format) and rename estimate columns
acs11 <- get_acs(
  geography = "tract",
  variables = tidy_vars,
  year = 2011,
  state = "AZ",
  county = counties,
  geometry = TRUE,
  output = "wide"
) %>%
  st_transform(st_crs(fishnet)) %>%
  rename(
    pop11 = pop,
    inc11 = income,
    house11 = housing
  ) %>%
  dplyr::select(GEOID, pop11, inc11, house11, geometry)

# Download 2021 ACS (wide format) and rename estimate columns
acs21 <- get_acs(
  geography = "tract",
  variables = tidy_vars,
  year = 2021,
  state = "AZ",
  county = counties,
  geometry = TRUE,
  output = "wide"
) %>%
  st_transform(st_crs(fishnet)) %>%
  rename(
    pop21 = pop,
    inc21 = income,
    house21 = housing
  ) %>%
  dplyr::select(GEOID, pop21, inc21, house21, geometry)

# Areal-weighted interpolation onto fishnet
fishnet_pop11 <- st_interpolate_aw(
  acs11[c("pop11", "inc11", "house11")],
  fishnet,
  extensive = TRUE
)
fishnet_pop21 <- st_interpolate_aw(
  acs21[c("pop21", "inc21", "house21")],
  fishnet,
  extensive = TRUE
)
```

# 10. Transportation & Infrastructure Features

```{r transport}
# Load existing light rail network
existing_lr <- st_read("data/LightRail_Existing/LightRail_Existing.shp")

existing_lr <- st_transform(existing_lr, st_crs(fishnet))

# Compute distance from each cell centroid to nearest existing light rail line
centroids <- st_centroid(fishnet)
fishnet$dist_lr_existing <- as.numeric(
  st_distance(centroids, st_union(existing_lr)))

# Proposed extension
new_lr <- st_read("data/LightRail_Extension/LightRail_Extension.shp")

new_lr <- st_transform(new_lr, st_crs(fishnet))

fishnet$dist_new <- as.numeric(st_distance(centroids, new_lr))
```

# 11. Spatial Lag of Development

```{r spatial-lag}
# Compute centroids once
centroids <- st_centroid(fishnet)
# Matrix of fishnet centroid coordinates
grid_xy <- st_coordinates(centroids)

# Extract fishnet_lc layers: dev1 and dev2 should already be numeric 0/1 columns
# No need to re-mutate dev1/dev2

# Points of converted cells in t1 and t2
t1_points <- fishnet_lc1 %>%
  filter(dev1 == 1) %>%        # dev1 is numeric vector
  st_centroid() %>%
  st_coordinates()
t2_points <- fishnet_lc2 %>%
  filter(dev2 == 1) %>%
  st_centroid() %>%
  st_coordinates()

# Compute spatial lag: average distance to 2 nearest developed cells
grid_lag1 <- nn_function(grid_xy, t1_points, k = 2)
grid_lag2 <- nn_function(grid_xy, t2_points, k = 2)

# Attach lag variables back to fishnet
fishnet <- fishnet %>%
  mutate(
    lagDev1 = grid_lag1,
    lagDev2 = grid_lag2
  )
```

# 12. County Fixed Effects

```{r county-fe}
cts <- counties(state="AZ", cb=TRUE) %>% st_transform(st_crs(fishnet)) %>%
  filter(NAME %in% c("Maricopa","Pinal"))
fishnet <- fishnet %>% st_join(cts["NAME"]) %>% rename(county=NAME)
```

# 13. Compile Modeling Data Sets

```{r compile}
# ─────────────────────────────────────────────────────────────────────────────
# 0. Recompute and prepare the 2011 population/census table, ensuring one row per cell_id
# ─────────────────────────────────────────────────────────────────────────────
fishnet_pop11 <- st_interpolate_aw(
  acs11[c("pop11","inc11","house11")],
  fishnet,
  extensive = TRUE)

# Attach the matching cell_id from fishnet
pop11_df <- fishnet_pop11 %>%
  st_drop_geometry() %>%
  mutate(cell_id = fishnet$cell_id) %>%
  dplyr::select(cell_id, pop11, inc11, house11) %>%
  distinct(cell_id, .keep_all = TRUE)

# ─────────────────────────────────────────────────────────────────────────────
# 1. Land‐cover flags (base_lc1)
# ─────────────────────────────────────────────────────────────────────────────
base_lc1 <- fishnet_lc1 %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, dev1, forest1, farm1, wet1, oth1, water1) %>%
  distinct(cell_id, .keep_all = TRUE)

# ─────────────────────────────────────────────────────────────────────────────
# 2. Change + distance + lag + county
# ─────────────────────────────────────────────────────────────────────────────
fishnet_df <- fishnet %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, development_change, county, dist_lr_existing, dist_new, lagDev1)

# ─────────────────────────────────────────────────────────────────────────────
# 3. Assemble the 2011 training dataset
# ─────────────────────────────────────────────────────────────────────────────
dat11 <- base_lc1 %>%
  left_join(fishnet_df, by = "cell_id") %>%
  left_join(pop11_df,   by = "cell_id") %>%
  filter(wet1 == 0) %>%
  # HERE: recode any NA → 0 on development_change
  mutate(
    development_change = as.character(development_change),  # to avoid factor quirks
    development_change = replace_na(development_change, "0"),
    development_change = factor(development_change, levels = c("0","1"))
  )

dat11 <- dat11 %>%
  # Impute median income for any missing cells
  mutate(
    inc11 = replace_na(inc11, median(inc11, na.rm = TRUE))
  )

# sanity check
table(dat11$development_change)
colSums(is.na(dat11))
```

# 14. Model Training & Validation

```{r modeling}
set.seed(2025)
train_i <- caret::createDataPartition(
  y    = dat11$development_change,
  p    = 0.70,
  list = FALSE
)
train <- dat11[train_i, ]
test  <- dat11[-train_i, ]

# Check class balance
prop.table(table(train$development_change))
prop.table(table(test$development_change))

# 14.2. Fit the Logistic Regression Model
model <- glm(
  development_change ~ 
    dist_lr_existing + dist_new + lagDev1 +
    pop11  + inc11   + house11 +
    dev1   + forest1 + farm1   + oth1   +
    county,
  data   = train,
  family = binomial(link = "logit")
)
summary(model)

# 14.3. Predict on Test Set
test$prob <- predict(model, test, type = "response")

# 14.4. Choose Threshold & Confusion Matrix
threshold <- 0.10
test$pred_class <- factor(
  ifelse(test$prob > threshold, "1", "0"),
  levels = c("0","1")
)
cm <- caret::confusionMatrix(
  test$pred_class,
  factor(test$development_change),
  positive = "1"
)
print(cm)

# 14.5. ROC Curve & AUC
library(plotROC)
roc_df <- data.frame(
  obs  = as.numeric(test$development_change),
  pred = test$prob
)
ggplot(roc_df, aes(d = obs, m = pred)) +
  geom_roc(n.cuts = 50) +
  style_roc(theme = theme_minimal()) +
  labs(title = "ROC Curve (Test Set)")

library(yardstick)
auc_val <- roc_auc_vec(test$development_change, test$prob)
cat("Test‐set AUC =", round(auc_val, 3), "\n")
```

> **To Report:**  
> - **Coefficients:** signs, significance, and e^(β) for interpretation  
> - **Confusion matrix:** accuracy, sensitivity (TPR), specificity (TNR) at your chosen threshold  
> - **AUC** from the ROC (should be ≥ 0.7 for a useful model)

# 15. Forecast to 2031 & Impact Assessment

```{r forecast}

# 15A. Build the raw t2 feature table (from fishnet_lc2, fishnet, fishnet_pop21) ---

# 1. LC flags
lc2_df <- fishnet_lc2 %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, dev2, forest2, farm2, wet2, oth2)

# 2. Infra, lag, county
feat2_df <- fishnet %>%
  st_drop_geometry() %>%
  rename(dist_hwy = dist_lr_existing) %>%    # keep same name as in t1 compile
  dplyr::select(cell_id, dist_hwy, dist_new, lagDev2, county)

# 3. Census via spatial join (one-to-one to fishnet)
pop21_df <- fishnet_pop21 %>%
  st_centroid() %>%
  st_join(dplyr::select(fishnet, cell_id), join = st_within) %>%
  st_drop_geometry() %>%
  dplyr::select(cell_id, pop21, inc21, house21) %>%
  distinct(cell_id, .keep_all = TRUE)

# 4. Left‐join all and filter water
dat21 <- lc2_df %>%
  left_join(feat2_df, by = "cell_id") %>%
  left_join(pop21_df,  by = "cell_id") %>%
  filter(wet2 == 0)

# --- 15B. Rename to match t1 variable names exactly ---

dat21 <- dat21 %>%
  rename(
    lagDev1  = lagDev2,   # model expects lagDev1
    pop11    = pop21,     
    inc11    = inc21,
    house11  = house21,
    dev1     = dev2,      # model uses dev1, forest1, farm1, oth1
    forest1  = forest2,
    farm1    = farm2,
    oth1     = oth2,
    dist_lr_existing = dist_hwy  # if your model uses dist_lr_existing
  )

# Drop the old t2-named cols to avoid confusion
dat21 <- dat21 %>% dplyr::select(
  cell_id,
  dist_lr_existing, dist_new, lagDev1,
  pop11, inc11, house11,
  dev1, forest1, farm1, oth1,
  county
)

# 15C. Impute any remaining NAs
dat21 <- dat21 %>%
  mutate(
    pop11   = replace_na(pop11,   0),
    house11 = replace_na(house11, 0),
    inc11   = replace_na(inc11,   median(inc11, na.rm=TRUE))
  )

# Verify zero NAs
cat("NAs in dat21:", sum(is.na(dat21)), "\n")

# --- 15D. Predict 2031 Development ---

dat21$prob31 <- predict(model, dat21, type = "response")

threshold <- 0.10
dat21$pred31 <- factor(
  ifelse(dat21$prob31 > threshold, "1", "0"),
  levels = c("0","1")
)

# --- 15E. Join back to fishnet and assess risk ---

forecast_sf <- left_join(fishnet, dat21, by = "cell_id")
```
> 1. **Map** of cells predicted to develop by 2031.  
> 2. **Table** showing `% in floodplain` and `% in protected areas`.  
> 3. **Narrative** tying these numbers to your three key recommendations.

```{r impact-assessment, warning=FALSE, message=FALSE}
gdb_path <- "data/Protected Areas/PADUS4_1_StateAZ.gdb"
st_layers(gdb_path)

# 2. Read the Fee‐simple layer (clean multipolygons only)
prot_fee <- st_read(
  dsn   = gdb_path,
  layer = "PADUS4_1Fee_State_AZ",   # simpler, pure multipolygon layer
  quiet = TRUE
)

# 3. Drop any Z/M dims and ensure POLYGON/MULTIPOLYGON
prot <- prot_fee %>%
  st_zm(drop = TRUE, what = "ZM") %>%    # strip Z/M
  st_cast("MULTIPOLYGON") %>%            # force to standard multipolygons
  st_transform(st_crs(forecast_sf))      # into your model CRS


# 4. Flag protected‐area risk
# 1. One-time spatial intersection call
ix <- st_intersects(forecast_sf, prot)

# 2. Logical vector: does each cell touch protected area?
touches_prot <- lengths(ix) > 0

# 3. Add prot_risk in two quick steps
forecast_sf$prot_risk <- (forecast_sf$pred31 == "1") & touches_prot

# 5. Summarize
risk_sum <- forecast_sf %>%
  filter(pred31 == "1") %>%
  st_drop_geometry() %>%
  summarize(
    total_cells = n(),
    pct_prot    = mean(prot_risk) * 100
  )
knitr::kable(risk_sum, digits = 1,
             caption = "Percent of 2031‐Predicted Cells in Fee‐Simple Protected Areas")

dev_area <- forecast_sf %>% 
  filter(pred31 == "1") %>% 
  st_union() %>% 
  st_as_sf()

ggplot() +
  # 1. white background & crisp outline of study area
  geom_sf(data = phx_msa, fill = "white", color = "black", size = 0.5) +
  
  # 2. plotted development forecast
  geom_sf(data = dev_area, fill = "darkgreen", color = NA) +
  
  # 3. updated legend with no "NA" class
  scale_fill_manual(
    values       = c("0" = "grey80", "1" = "darkgreen"),
    labels       = c("No Dev", "Developed"),
    name         = "2031 Dev",
    na.value     = "white",      # paint any missing cells white
    na.translate = FALSE         # drop the “NA” entry from the legend
  ) +
  
  # 4. titles & clean theme
  labs(
    title    = "Projected 2031 Development",
    subtitle = "Threshold = 10%"
  ) +
  theme_void() +
  theme(
    plot.title    = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    legend.position = "right"
  )
```
```{r}
save.image(file = "data/my_workspace.RData")

load("data/my_workspace.RData")
```

# Recommendations

1. Establish green buffers around protected lands given ~`r round(risk_sum$pct_prot,1)`% overlap.  
2. Incentivize infill and higher density within 0.5 mi of the new corridor to curb leapfrog sprawl.

---

<small>Adapted from Houston Urban Growth Modeling example (Fichman et al.).</small>
